## Final Reflection

### (1) Prototype Session Review
The IP3 prototype demonstrated:
- stable core functionality  
- effective video editing logic  
- participants completing tasks successfully  

Remaining issues:
- unclear Undo prompts  
- insufficient feedback after cutting  

Key realization:
> In XR, clear feedback and proper pacing matter more than adding more features.

---

### (2) Methodological Reflection
Using task-based usability testing with mixed data collection produced:
- actionable design insights  
- quantifiable performance measures  
- deeper understanding of user psychology  

Limitations:
1. Small sample size → limited representativeness  
2. Observational dimensions insufficient → relied on subjective interpretation  

---

### (3) Concept Evaluation
XR spatial layout:
- helps users naturally understand video structure  
- supports intuitive manipulation  

However:
- high precision tasks are visually + cognitively demanding  
- Undo & Mark remain abstract  
- Immersion sometimes reduces predictability  

Conclusion:
> Concept partially validated—spatial intuition effective, but controllability must improve.

---

### (4) Improvements and Extensions

#### A. Improve onboarding  
Add lightweight guidance, e.g.:
- floating tips  
- initial highlight animations  

Reduces mental overhead for first-time users.

#### B. Strengthen interactive feedback  
Add:
- light vibration  
- micro-animations  
- haptic patterns  

to confirm operations.

#### C. Explore AR extension  
Shift from:
- “closed XR space” → “collaborative AR environment”  

Enables shared editing and broader context-aware use cases.

---
